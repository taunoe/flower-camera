{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KntdZZ5ruM7Z"
      },
      "source": [
        "## Preparing and testing the quantized TFLite model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "0. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import zipfile\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TF_MODEL = \"scene_recognition\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srHkdaf_kk97"
      },
      "source": [
        "1. Unzip the test dataset (test_samples.zip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxnVbqxkkspY"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(\"test_samples.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "    \n",
        "test_dir = \"dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzTiU6qQk_Bv"
      },
      "source": [
        "2. Rescale the pixel values from [0, 255] to [-1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYHpua21lGXp"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.keras.utils.image_dataset_from_directory(test_dir,\n",
        "                                                      interpolation=\"bilinear\",\n",
        "                                                      image_size=(MODEL_INPUT_WIDTH, MODEL_INPUT_HEIGHT))\n",
        "test_ds  = test_ds.map(lambda x, y: (rescale(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riqPFiWllkdg"
      },
      "source": [
        "3. Quantize the TensorFlow model with the TFLite converter to TensorFlow Lite format (FlatBuffers). Apply the 8-bit quantization to the entire model except for the output layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALWbwZKBuNl8"
      },
      "outputs": [],
      "source": [
        "repr_ds = test_ds.unbatch()\n",
        "\n",
        "def representative_data_gen():\n",
        "  for i_value, o_value in repr_ds.batch(1).take(48):\n",
        "    yield [i_value]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(TF_MODEL)\n",
        "converter.representative_dataset = tf.lite.RepresentativeDataset(representative_data_gen)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "\n",
        "tfl_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQg4FbwzluB8"
      },
      "source": [
        "4. Get the TFLite model size in bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFIpV1uUlxiZ"
      },
      "outputs": [],
      "source": [
        "size_tfl_model = len(tfl_model)\n",
        "print(len(tfl_model), \"bytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Br6hq8Cl4nU"
      },
      "source": [
        "5. Initialize the TFLite interpreter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACsaQjxzP2Wd"
      },
      "outputs": [],
      "source": [
        "# Initialize the TFLite interpreter\n",
        "interpreter = tf.lite.Interpreter(model_content=tfl_model)\n",
        "\n",
        "# Allocate the tensors\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxxhFk-7l9J2"
      },
      "source": [
        "6. Get input quantization parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrH3uM8Gl_Hg"
      },
      "outputs": [],
      "source": [
        "# Get input/output layer information\n",
        "i_details = interpreter.get_input_details()[0]\n",
        "o_details = interpreter.get_output_details()[0]\n",
        "\n",
        "# Get input quantization parameters.\n",
        "i_quant = i_details[\"quantization_parameters\"]\n",
        "i_scale      = i_quant['scales'][0]\n",
        "i_zero_point = i_quant['zero_points'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQcFhKfumT1B"
      },
      "source": [
        "7. Evaluate the accuracy of the quantized TFLite model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vlIBfMHmWT-"
      },
      "outputs": [],
      "source": [
        "test_ds0 = val_ds.unbatch()\n",
        "\n",
        "num_correct_samples = 0\n",
        "num_total_samples   = len(list(test_ds0.batch(1)))\n",
        "\n",
        "for i_value, o_value in test_ds0.batch(1):\n",
        "  i_value = (i_value / i_scale) + i_zero_point\n",
        "  i_value = tf.cast(i_value, dtype=tf.int8)\n",
        "  interpreter.set_tensor(i_details[\"index\"], i_value)\n",
        "  interpreter.invoke()\n",
        "  o_pred = interpreter.get_tensor(o_details[\"index\"])[0]\n",
        "\n",
        "  if np.argmax(o_pred) == o_value:\n",
        "    num_correct_samples += 1\n",
        "\n",
        "print(\"Accuracy:\", num_correct_samples/num_total_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM-ZaNUHmkBm"
      },
      "source": [
        "8. Convert the TFLite model to C-byte array with xxd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kAnQgmI0QK_"
      },
      "outputs": [],
      "source": [
        "open(\"model.tflite\", \"wb\").write(tfl_model)\n",
        "!apt-get update && apt-get -qq install xxd\n",
        "!xxd -c 60 -i model.tflite > scene_recognition.h"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "chapter05.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
