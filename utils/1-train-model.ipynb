{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rmt lk 184 kuni 187.\n",
    "NÃ¤idiskood: https://github.com/PacktPublishing/TinyML-Cookbook/blob/main/Chapter05/ColabNotebooks/prepare_model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onen in Colab and upload dataset.zip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import zipfile\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ALPHA = 0.35\n",
    "MODEL_INPUT_WIDTH = 48\n",
    "MODEL_INPUT_HEIGHT = 48\n",
    "TFL_MODEL_FILE = \"scene_recognition.tflite\"\n",
    "TFL_MODEL_HEADER_FILE = \"scene_recognition_model.h\"\n",
    "TF_MODEL = \"scene_recognition\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Unzip the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"dataset.zip\", 'r') as zip_ref:\n",
    "  zip_ref.extractall(\".\")\n",
    "\n",
    "data_dir = \"dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Resizes the input images to 48x48 with the bilinear interpolation. Prepare the training (80%) and validation (20%) datsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  interpolation=\"bilinear\",\n",
    "  image_size=(MODEL_INPUT_WIDTH, MODEL_INPUT_HEIGHT)) # const\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  interpolation=\"bilinear\",\n",
    "  image_size=(MODEL_INPUT_WIDTH, MODEL_INPUT_HEIGHT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Get the name of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Rescale the pixel values from [0, 255] to [-1, 1] because the pre-trained model expects this interval data range for the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = tf.keras.layers.Rescaling(1./255, offset= -1)\n",
    "train_ds = train_ds.map(lambda x, y: (rescale(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (rescale(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Import the MobileNet v2 pre-trained model with the weights trained on the ImageNet dataset and alpha=0.35. Furthermore, set the input image at the lowest resolution allowed by the pre-trained model (48, 48, 3) and exclude the top (fully-connected) layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(input_shape=(48, 48, 3),\n",
    "                         include_top=False,\n",
    "                         weights='imagenet',\n",
    "                         alpha=0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Freeze the weights so that you do not update these values during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "feat_extr = base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Augment the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmen = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (augmen(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (augmen(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Prepare the classification head with a global pooling followed by a dense layer with a softmax activation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_avg_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "dense_layer = tf.keras.layers.Dense(num_classes,activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Build the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(MODEL_INPUT_WIDTH, MODEL_INPUT_HEIGHT, 3))\n",
    "x = global_avg_layer(feat_extr.layers[-1].output)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = dense_layer(x)\n",
    "model = tf.keras.Model(inputs=feat_extr.inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Compile the model with a 0.0005 learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0005\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Train the model with 10 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.  Save the TensorFlow model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(TF_MODEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
